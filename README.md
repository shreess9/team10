# ðŸ¤– V-AIVA: Vision & Voice AI Assistant

![V-AIVA Banner](https://user-images.githubusercontent.com/0000000/vision-voice-ai.jpg)  
*A Smart Assistant that Sees, Hears, and Speaks.*  
<br/>

> V-AIVA is an accessible, web-based AI assistant that integrates **real-time object detection**, **speech recognition**, and **natural language response**. Designed for inclusivity, it empowers usersâ€”especially the visually impairedâ€”with **auditory feedback** for both visual and spoken inputs.

---

## ðŸŒŸ Key Features

- ðŸ§  **Real AI Chat** with language model backend (e.g., LLaMA/GPT)
- ðŸ—£ï¸ **Speech-to-Text** via Web Speech API
- ðŸ”Š **Text-to-Speech** response using Web Speech Synthesis
- ðŸ“¸ **Object Detection** with TensorFlow.js + COCO-SSD
- âš¡ **Real-time Feedback** via canvas overlay and audio
- ðŸŒ™ **Dark Mode** for Accessibility
- ðŸ“± **Mobile-Ready** architecture (React Native transition-ready)

---

## ðŸš€ Live Demo

[ðŸ”— Click here to try V-AIVA](https://your-deployment-link.vercel.app/)  
*(Note: Works best on Chromium browsers with webcam and mic access.)*

---

## ðŸ§° Tech Stack

| Frontend       | Backend       | ML/AI         | Tools & Plugins         |
|----------------|---------------|---------------|--------------------------|
| React.js       | Node.js       | COCO-SSD (TF.js) | Vite, Web Speech API     |
| HTML + SCSS    | Express.js    | GPT/LLaMA via Ollama | TensorFlow.js, Canvas API |
| React Hooks    | REST APIs     | TFLite (planned mobile) | dotenv, concurrently      |

---

## ðŸ“ Project Structure

```
vision-voice-mvp/
â”œâ”€â”€ public/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ CameraFeed.jsx
â”‚   â”‚   â”œâ”€â”€ VoiceCommand.jsx
â”‚   â”‚   â””â”€â”€ ObjectOverlay.jsx
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ App.scss
â”‚   â””â”€â”€ main.jsx
â”œâ”€â”€ server/
â”‚   â””â”€â”€ index.js
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.js
â””â”€â”€ README.md
```

---

## ðŸ› ï¸ Installation & Setup

> Follow the steps below to clone and run V-AIVA locally.

### âœ… Prerequisites

- [Node.js](https://nodejs.org/) (v18+)
- [Git](https://git-scm.com/)
- Webcam & Microphone access
- Browser: Chrome or Edge recommended

### ðŸ’» Clone the Repository

```bash
git clone https://github.com/shreess9/team10.git
cd team10/vision-voice-mvp
```

### ðŸ“¦ Install Dependencies

```bash
npm install
```

### ðŸ§  Run the Backend (AI/Chat Server)

```bash
cd server
npm install
npm run start
```

### ðŸ’¡ Run the Frontend

```bash
cd ..
npm run dev
```

> Visit `http://localhost:5173` in your browser.

---

## ðŸ§ª How It Works

### ðŸŽ¥ Object Detection

```js
import * as cocoSsd from '@tensorflow-models/coco-ssd';
const model = await cocoSsd.load();
const predictions = await model.detect(videoRef.current);
```

- Uses `TensorFlow.js` COCO-SSD to detect real-world objects in webcam feed.
- Detected objects are drawn using `<canvas>`.

### ðŸ—£ï¸ Voice Commands

```js
const recognition = new window.webkitSpeechRecognition();
recognition.onresult = (e) => {
  const voiceText = e.results[0][0].transcript;
  handleUserQuery(voiceText);
};
```

- Captures voice and converts to text.
- Queries backend or object detection module.

### ðŸ”Š Voice Response

```js
const utterance = new SpeechSynthesisUtterance(response);
speechSynthesis.speak(utterance);
```

- Speaks back results to help visually impaired users.

---

## ðŸ”Œ Plugins & Packages

| Package               | Purpose                        |
|-----------------------|--------------------------------|
| @tensorflow-models/coco-ssd | Object detection model    |
| react-speech-recognition | Voice input handling       |
| react-speech-kit       | Text-to-speech utility       |
| react-router-dom       | Navigation                   |
| express + dotenv       | Backend chat processing      |
| vite                   | Blazing-fast frontend dev    |

---

## ðŸ“² Mobile Deployment (Coming Soon)

- `React Native + Expo`
- `expo-camera`, `expo-speech`, `TensorFlow Lite`
- Voice-first UI for the blind
- Offline inference support with `tflite-react-native`

---

## ðŸ§  Future Enhancements

- ðŸ¤ Integration with **Ollama**, **LangChain**, or **LLaMA CPP**
- ðŸŒ Translation and multilingual voice support
- ðŸ” User personalization with local storage
- ðŸ“± Full mobile deployment with **TFLite**

---

## ðŸ‘¨â€ðŸ’» Kudos to Team V-AIVA ðŸ‘

This project is brought to life by a passionate and hardworking team:

**Team Members**  
- ðŸ§  Pavitha  
- ðŸ—£ï¸ Sanjay  
- ðŸŽ¯ Rohith  
- ðŸŽ¨ Arun  
- ðŸ’» Vikasini  
- ðŸš€ Shree Sangamithrai *(Team Lead)*

> Built with â¤ï¸, caffeine â˜•, and the vision of a more inclusive AI world.

---

## ðŸŒ License

This project is licensed under the [MIT License](LICENSE).

---

## ðŸ“£ Connect With Us

Feel free to raise issues or suggest features via the [GitHub Issues Page](https://github.com/shreess9/team10/issues).

---

## ðŸ™Œ Acknowledgements

- OpenAI, TensorFlow, Google, Mozilla Web APIs  
- Hackathons & mentors who inspired this innovation  
- Community of developers building inclusive AI tools  

> _"The best way to predict the future is to invent it."_ â€” Alan Kay

---
